from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain

import csv
import os

os.environ["OPENAI_API_KEY"] = "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"

file_path = "/content/服飾資料數據.csv"

texts = []
with open(file_path, newline='', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    for row in reader:
        text = row[0]  # 假設 CSV 的每一列只有一個文本內容
        texts.append(text)

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(texts, embeddings)  # 使用 Chroma.from_texts 方法
n_results = 3

qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.2), vectorstore.as_retriever())
chat_history = []

while True:
    query = input('\nQuestion: ')
    if not query:
        break
    result = qa({"question": query + '(用繁體中文回答)', "chat_history": chat_history})
    print('A:', result['answer'])
    chat_history.append((query, result['answer']))
