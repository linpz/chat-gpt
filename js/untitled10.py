# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TVL2CzKQoYp1UhNULtcHnq-G829DaSXL
"""

!pip install langchain
!pip install sentence_transformers chromadb tiktoken openai

!pip install pypdf

pip install Pillow

!pip install pdfminer

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import TextLoader,PyPDFLoader
from langchain.text_splitter import  RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders.image import UnstructuredImageLoader



import os
os.environ["OPENAI_API_KEY"] = "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" #own openAI key



file_path = "/data(2).pdf" #文件路徑


loader = file_path.endswith(".pdf") and PyPDFLoader(file_path) or TextLoader(file_path) #loader


splitter = RecursiveCharacterTextSplitter(chunk_size=500 , chunk_overlap=0) #splitter
texts = loader.load_and_split(splitter)
image = loader.load()

#embedding & vectorstore
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(texts, embeddings)
n_results = 3

#對話chain
qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.2), vectorstore.as_retriever())
chat_history = []
while True:
    query = input('\nQuestion: ')
    if not query:
        break
    result = qa({"question": query+ '(用繁體中文回答)' , "chat_history" : chat_history})
    #print(result['answer']) 要抓回傳資料，變數為 result['answer']
    print('A:',result['answer'])
    chat_history.append((query, result['answer']))